{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNVTKH8EDGvX"
      },
      "source": [
        "# Fine tune an Open Source Embedding Model\n",
        "\n",
        "https://colab.research.google.com/drive/1VVfR3i07b7OsDsRLHm0ADvPdNqA2RgmI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81ORK07HDPRR"
      },
      "source": [
        "# Check Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-SnyR6NsFfW",
        "outputId": "40e442a0-6b91-4885-9953-e1fbaff1fb71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Available: True\n",
            "GPU: Tesla T4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup validated successfully!\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Check GPU availability\n",
        "\n",
        "flg_cuda_is_available = torch.cuda.is_available()\n",
        "if flg_cuda_is_available:\n",
        "  print(f\"CUDA Available: {flg_cuda_is_available}\")\n",
        "  print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Validate model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "print(\"Setup validated successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOgYl2xb3cNN",
        "outputId": "049b10dc-7860-40c1-a447-2e3f61354b01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "transformers.__version__='4.55.4'\n",
            "sentence_transformers.__version__='5.1.0'\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "import sentence_transformers\n",
        "\n",
        "print(f\"{transformers.__version__=}\")\n",
        "print(f\"{sentence_transformers.__version__=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfusBXtQDTnP"
      },
      "source": [
        "# Load Model\n",
        "\n",
        "[Sentence Transformers Pretrained Models](https://www.sbert.net/docs/sentence_transformer/pretrained_models.html)\n",
        "\n",
        "[bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5) is a small yet performant embedding model.\n",
        "* Only English\n",
        "* Dimension: 384\n",
        "* Context: 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu8kMre0zHMv",
        "outputId": "95d90db4-283b-454f-ba60-ae3dbfb6bdc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the pre-trained embedding model\n",
        "model_id = \"BAAI/bge-small-en-v1.5\"\n",
        "model_bsl = SentenceTransformer(model_id)\n",
        "print(\"Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d0k-HsKEOkj"
      },
      "source": [
        "# Load Dataset\n",
        "\n",
        "[philschmid/finanical-rag-embedding-dataset](https://huggingface.co/datasets/philschmid/finanical-rag-embedding-dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aJoepFhsZxI",
        "outputId": "de2dd836-95a1-4701-cc80-a8d422e35897"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['question', 'context'],\n",
              "        num_rows: 7000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "# Load your dataset (replace with your specific dataset)\n",
        "dataset = load_dataset(\"philschmid/finanical-rag-embedding-dataset\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmHfIfKqwwrP",
        "outputId": "c39b60fd-d63b-449f-c219-bae772c0edff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'question': 'What area did NVIDIA initially focus on before expanding to other computationally intensive fields?', 'context': 'Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields.'}\n"
          ]
        }
      ],
      "source": [
        "print(dataset[\"train\"][0])  # Inspect the data structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjFEGBSbEdwu"
      },
      "source": [
        "# How Does IR evaluator works?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9qOIawOv0uq",
        "outputId": "252976f1-5791-46ca-adce-73bf50b8e697"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'cosine_accuracy@1': 0.5,\n",
              " 'cosine_accuracy@3': 1.0,\n",
              " 'cosine_accuracy@5': 1.0,\n",
              " 'cosine_accuracy@10': 1.0,\n",
              " 'cosine_precision@1': 0.5,\n",
              " 'cosine_precision@3': 0.3333333333333333,\n",
              " 'cosine_precision@5': 0.2,\n",
              " 'cosine_precision@10': 0.1,\n",
              " 'cosine_recall@1': 0.5,\n",
              " 'cosine_recall@3': 1.0,\n",
              " 'cosine_recall@5': 1.0,\n",
              " 'cosine_recall@10': 1.0,\n",
              " 'cosine_ndcg@10': 0.8154648767857288,\n",
              " 'cosine_mrr@10': 0.75,\n",
              " 'cosine_map@100': 0.75}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
        "\n",
        "# Define queries, documents, and relevant pairs\n",
        "queries = {\"query1\": \"What is quantum mechanics?\",\n",
        "           \"query2\": \"Who was the first Roman Emperor?\"\n",
        "           }\n",
        "docs = {\"doc1\": \"Quantum mechanics is the branch of physics that studies the sub-atomic behaviour\",\n",
        "        \"doc2\": \"The sun rises in the east.\",\n",
        "        \"doc3\": \"Augustus (formerly named Octavious, who changed his name after Julius Caesar after his death), is considered the one who ended the Roman Republic and started the empyre\"}\n",
        "relevant_docs = {\"query1\": [\"doc1\"],\n",
        "                 \"query2\": [\"doc2\"]}\n",
        "\n",
        "# Initialize evaluator\n",
        "evaluator_dummy = InformationRetrievalEvaluator(queries, docs, relevant_docs)\n",
        "\n",
        "# Evaluate the model\n",
        "model_bsl.evaluate(evaluator_dummy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhXoHkPEEk4B"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w33haYnh5UxV"
      },
      "outputs": [],
      "source": [
        "ds = dataset['train']\n",
        "# Add an id column to the dataset\n",
        "ds = ds.add_column(\"id\", range(len(ds)))\n",
        "\n",
        "# split dataset into a 10% test set\n",
        "# 90% train, 10% test + validation\n",
        "ds_train_test = ds.train_test_split(test_size=0.1, seed=42)\n",
        "# Split the 10% test + valid in half test, half valid\n",
        "ds_valid_test = ds_train_test['test'].train_test_split(test_size=0.5, seed=42)\n",
        "# gather everyone if you want to have a single DatasetDict\n",
        "ds_split = DatasetDict({\n",
        "    'train': ds_train_test['train'],\n",
        "    'test': ds_valid_test['test'],\n",
        "    'valid': ds_valid_test['train']})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9HFkhck7Cdt",
        "outputId": "2832281c-6638-4906-cbaa-ecca9b672486"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['question', 'context', 'id'],\n",
              "        num_rows: 6300\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['question', 'context', 'id'],\n",
              "        num_rows: 350\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['question', 'context', 'id'],\n",
              "        num_rows: 350\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRjrSS3_Eoy9"
      },
      "source": [
        "# Baseline evaluation\n",
        "\n",
        "Check model performance before FT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huy12o5V7o_W",
        "outputId": "3a5e3e98-589a-4347-87e9-d2589ea00006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline model evals: BAAI/bge-small-en-v1.5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'cosine_accuracy@1': 0.5942857142857143,\n",
              " 'cosine_accuracy@3': 0.7371428571428571,\n",
              " 'cosine_accuracy@5': 0.8,\n",
              " 'cosine_accuracy@10': 0.8457142857142858,\n",
              " 'cosine_precision@1': 0.5942857142857143,\n",
              " 'cosine_precision@3': 0.24571428571428572,\n",
              " 'cosine_precision@5': 0.15999999999999998,\n",
              " 'cosine_precision@10': 0.08457142857142856,\n",
              " 'cosine_recall@1': 0.5942857142857143,\n",
              " 'cosine_recall@3': 0.7371428571428571,\n",
              " 'cosine_recall@5': 0.8,\n",
              " 'cosine_recall@10': 0.8457142857142858,\n",
              " 'cosine_ndcg@10': 0.7212104601552022,\n",
              " 'cosine_mrr@10': 0.681048752834467,\n",
              " 'cosine_map@100': 0.6858932357463235}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_test = ds_split['test']\n",
        "\n",
        "# Create a mapping of relevant document (1 in our case) for each query\n",
        "relevant_docs = {}  # Query ID to relevant documents (qid => set([relevant_cids])\n",
        "corpus = {}\n",
        "queries = {}\n",
        "\n",
        "for row in ds:\n",
        "    q_id = row['id']\n",
        "    corpus[q_id] = row['context']\n",
        "\n",
        "for row in ds_test:\n",
        "    q_id = row['id']\n",
        "    queries[q_id] = row['question']\n",
        "    relevant_docs[q_id] = [q_id]\n",
        "\n",
        "# Initialize evaluator\n",
        "evaluator_test = InformationRetrievalEvaluator(queries, corpus, relevant_docs\n",
        "                                              # ,score_functions={\"cosine\": cos_sim}\n",
        "                                              )\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "evals_test_bsl = model_bsl.evaluate(evaluator_test)\n",
        "\n",
        "print(f\"Baseline model evals: {model_id}\")\n",
        "evals_test_bsl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWzSfiWPUWue"
      },
      "source": [
        "# Training:\n",
        "\n",
        "[MultipleNegativesRankingLoss](https://sbert.net/docs/package_reference/sentence_transformer/losses.html#multiplenegativesrankingloss)\n",
        "\n",
        "* Train and valid: For training process\n",
        "* Test: Benchmark against baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196,
          "referenced_widgets": [
            "29ca2a51b8234e80a8aecc0685611054",
            "a850ec4df40e4baf86f217b1ab00642d",
            "9ea54892afb142b1b0b69aa2c809ed9b",
            "430f45fa8dc64c498b364658c4cf7c4c",
            "7862bfbf5e80473d9e56cd57d58e1f25",
            "2e08e0c736164354b57555cf759a9219",
            "75b9e1b8c9b4462e867ceb3ff44e4471",
            "2edca4b8845748289b59c1c5175c0925",
            "ad4ce50fc88545bf8700efd7762aef93",
            "252abbfb995442c18c6cbfcf168af58c",
            "2806b7a9ac604946b5123311b89c39af"
          ]
        },
        "id": "iLCywHRmMX0F",
        "outputId": "153785d2-4590-4d5e-d448-f7c4b4e02441"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29ca2a51b8234e80a8aecc0685611054",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:sentence_transformers.data_collator:Column 'anchor' is at index 1, whereas a column with this name is usually expected at index 0. Note that the column order can be important for some losses, e.g. MultipleNegativesRankingLoss will always consider the first column as the anchor and the second as the positive, regardless of the dataset column names. Consider renaming the columns to match the expected order, e.g.:\n",
            "dataset = dataset.select_columns(['anchor', 'positive', 'negative'])\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:57, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Cosine Accuracy@1</th>\n",
              "      <th>Cosine Accuracy@3</th>\n",
              "      <th>Cosine Accuracy@5</th>\n",
              "      <th>Cosine Accuracy@10</th>\n",
              "      <th>Cosine Precision@1</th>\n",
              "      <th>Cosine Precision@3</th>\n",
              "      <th>Cosine Precision@5</th>\n",
              "      <th>Cosine Precision@10</th>\n",
              "      <th>Cosine Recall@1</th>\n",
              "      <th>Cosine Recall@3</th>\n",
              "      <th>Cosine Recall@5</th>\n",
              "      <th>Cosine Recall@10</th>\n",
              "      <th>Cosine Ndcg@10</th>\n",
              "      <th>Cosine Mrr@10</th>\n",
              "      <th>Cosine Map@100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.321800</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.957143</td>\n",
              "      <td>0.974286</td>\n",
              "      <td>0.982857</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.319048</td>\n",
              "      <td>0.194857</td>\n",
              "      <td>0.098286</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.957143</td>\n",
              "      <td>0.974286</td>\n",
              "      <td>0.982857</td>\n",
              "      <td>0.938499</td>\n",
              "      <td>0.923773</td>\n",
              "      <td>0.924779</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 63.00s\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformerTrainer, losses, SentenceTransformerModelCardData\n",
        "from sentence_transformers import SentenceTransformerTrainingArguments\n",
        "\n",
        "\n",
        "model = SentenceTransformer(\n",
        "  model_id,\n",
        "  model_kwargs={\n",
        "      \"attn_implementation\":\n",
        "      \"sdpa\"  # scaled_dot_product_attention Pytroch native impl\n",
        "      },\n",
        "  model_card_data=SentenceTransformerModelCardData(\n",
        "      language=\"en\",\n",
        "      license=\"apache-2.0\",\n",
        "      model_name=\"BGE small v1.5 Financial\",\n",
        "  ),\n",
        ")\n",
        "train_loss = losses.MultipleNegativesRankingLoss(model) # anchor + positive\n",
        "\n",
        "\n",
        "# Training dataset\n",
        "ds_train = (ds_split['train']\n",
        "            .select_columns([\"context\", \"question\"])\n",
        "            .rename_column(\"context\", \"positive\")\n",
        "            .rename_column(\"question\", \"anchor\")\n",
        "            )\n",
        "\n",
        "# Evaluator\n",
        "ds_valid = ds_split['valid']\n",
        "\n",
        "relevant_docs = {}\n",
        "corpus = {}\n",
        "queries = {}\n",
        "for row in ds_valid:\n",
        "    q_id = row['id']\n",
        "    corpus[q_id] = row['context']\n",
        "    queries[q_id] = row['question']\n",
        "    relevant_docs[q_id] = [q_id]\n",
        "\n",
        "evaluator_valid = InformationRetrievalEvaluator(\n",
        "    queries, corpus, relevant_docs\n",
        "                                              )\n",
        "\n",
        "# Define training arguments\n",
        "args = SentenceTransformerTrainingArguments(\n",
        "    output_dir=\"bge-small-financial\", # output directory and hugging face model ID\n",
        "    num_train_epochs=1,                         # number of epochs\n",
        "    per_device_train_batch_size=32,             # train batch size\n",
        "    gradient_accumulation_steps=16,             # for a global batch size of 512\n",
        "    per_device_eval_batch_size=16,              # evaluation batch size\n",
        "    warmup_ratio=0.1,                           # warmup ratio\n",
        "    learning_rate=2e-5,                         # learning rate, 2e-5 is a good value\n",
        "    lr_scheduler_type=\"cosine\",                 # use cosine learning rate scheduler\n",
        "    optim=\"adamw_torch_fused\",                  # use fused adamw optimizer\n",
        "    eval_strategy=\"epoch\",                      # evaluate after each epoch\n",
        "    save_strategy=\"epoch\",                      # save after each epoch\n",
        "    logging_steps=10,                           # log every 10 steps\n",
        "    save_total_limit=3,                         # save only the last 3 models\n",
        "    load_best_model_at_end=True,                # load the best model when training ends\n",
        "    report_to=\"none\",\n",
        "    metric_for_best_model='eval_cosine_recall@1'\n",
        ")\n",
        "\n",
        "\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=model,\n",
        "    args=args,  # training arguments\n",
        "    train_dataset=ds_train,\n",
        "    loss=train_loss,\n",
        "    evaluator=evaluator_valid,\n",
        ")\n",
        "\n",
        "# start training\n",
        "tm_start = time.perf_counter()\n",
        "trainer.train()\n",
        "tm_end = time.perf_counter()\n",
        "tm_process = tm_end - tm_start\n",
        "print(f\"Training time: {tm_process:.2f}s\")\n",
        "\n",
        "\n",
        "# save the best model\n",
        "trainer.save_model()\n",
        "\n",
        "fine_tuned_model = SentenceTransformer(\n",
        "    args.output_dir, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLb5q1n5d_HF",
        "outputId": "581382aa-8240-424a-eb13-ffa33757504d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SentenceTransformerModelCardData(language=[], license=None, model_name=None, model_id=None, train_datasets=[], eval_datasets=[], task_name='semantic textual similarity, semantic search, paraphrase mining, text classification, clustering, and more', tags=['sentence-transformers', 'sentence-similarity', 'feature-extraction', 'dense'], local_files_only=False, generate_widget_examples=True, base_model=None, base_model_revision=None, non_default_hyperparameters={}, all_hyperparameters={}, eval_results_dict={}, training_logs=[], widget=[], predict_example=None, label_example_list=[], code_carbon_callback=None, citations={}, best_model_step=None, first_save=True, widget_step=-1, pipeline_tag='sentence-similarity', library_name='sentence-transformers', version={'python': '3.12.11', 'sentence_transformers': '5.1.0', 'transformers': '4.55.4', 'torch': '2.8.0+cu126', 'accelerate': '1.10.1', 'datasets': '4.0.0', 'tokenizers': '0.21.4'})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fine_tuned_model.model_card_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iUzJb1sFHjo"
      },
      "source": [
        "# Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cdSfwknOfCQ",
        "outputId": "9fae24b6-d0e3-45ab-fcc8-7627b25d1c43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FT model evals: BAAI/bge-small-en-v1.5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'cosine_accuracy@1': 0.6542857142857142,\n",
              " 'cosine_accuracy@3': 0.7971428571428572,\n",
              " 'cosine_accuracy@5': 0.8457142857142858,\n",
              " 'cosine_accuracy@10': 0.8914285714285715,\n",
              " 'cosine_precision@1': 0.6542857142857142,\n",
              " 'cosine_precision@3': 0.2657142857142857,\n",
              " 'cosine_precision@5': 0.16914285714285712,\n",
              " 'cosine_precision@10': 0.08914285714285713,\n",
              " 'cosine_recall@1': 0.6542857142857142,\n",
              " 'cosine_recall@3': 0.7971428571428572,\n",
              " 'cosine_recall@5': 0.8457142857142858,\n",
              " 'cosine_recall@10': 0.8914285714285715,\n",
              " 'cosine_ndcg@10': 0.7718514612605226,\n",
              " 'cosine_mrr@10': 0.7335589569161,\n",
              " 'cosine_map@100': 0.7368102729714265}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "evals_test_ft = fine_tuned_model.evaluate(evaluator_test)\n",
        "\n",
        "print(f\"FT model evals: {model_id}\")\n",
        "evals_test_ft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryueV0dpFNMu"
      },
      "source": [
        "# Conclusions. Use FT when:\n",
        "* Need a small but performant model\n",
        "* Specific vocabulary or slangs\n",
        "* Easy to build a dataset\n",
        "* No need to frequently update knowledge base\n",
        "\n",
        "# Propietary Models\n",
        "Some providers do not offer yet an embedding fine tunning service.\n",
        "For example, GCP offers one on Vertext platform: [Tune text embeddings](https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-embeddings)\n",
        "\n",
        "# References:\n",
        "[Why, When and How to Fine-Tune a Custom Embedding Model](https://weaviate.io/blog/fine-tune-embedding-model)\n",
        "[Out of the box acceleration and memory savings of 🤗 decoder models with PyTorch 2.0](https://pytorch.org/blog/out-of-the-box-acceleration/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUPzqM9IeW7I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "252abbfb995442c18c6cbfcf168af58c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2806b7a9ac604946b5123311b89c39af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29ca2a51b8234e80a8aecc0685611054": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a850ec4df40e4baf86f217b1ab00642d",
              "IPY_MODEL_9ea54892afb142b1b0b69aa2c809ed9b",
              "IPY_MODEL_430f45fa8dc64c498b364658c4cf7c4c"
            ],
            "layout": "IPY_MODEL_7862bfbf5e80473d9e56cd57d58e1f25"
          }
        },
        "2e08e0c736164354b57555cf759a9219": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2edca4b8845748289b59c1c5175c0925": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "430f45fa8dc64c498b364658c4cf7c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_252abbfb995442c18c6cbfcf168af58c",
            "placeholder": "​",
            "style": "IPY_MODEL_2806b7a9ac604946b5123311b89c39af",
            "value": " 1/1 [00:00&lt;00:00,  8.65example/s]"
          }
        },
        "75b9e1b8c9b4462e867ceb3ff44e4471": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7862bfbf5e80473d9e56cd57d58e1f25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "9ea54892afb142b1b0b69aa2c809ed9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2edca4b8845748289b59c1c5175c0925",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad4ce50fc88545bf8700efd7762aef93",
            "value": 1
          }
        },
        "a850ec4df40e4baf86f217b1ab00642d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e08e0c736164354b57555cf759a9219",
            "placeholder": "​",
            "style": "IPY_MODEL_75b9e1b8c9b4462e867ceb3ff44e4471",
            "value": "Computing widget examples: 100%"
          }
        },
        "ad4ce50fc88545bf8700efd7762aef93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
