{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"10cgEA69-wBAlHFZ2pdKNC3jZnu5RzuIZ","timestamp":1756901412055}],"gpuType":"T4","authorship_tag":"ABX9TyPs4VMzouEyoa6W+T8X7/RK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"29ca2a51b8234e80a8aecc0685611054":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a850ec4df40e4baf86f217b1ab00642d","IPY_MODEL_9ea54892afb142b1b0b69aa2c809ed9b","IPY_MODEL_430f45fa8dc64c498b364658c4cf7c4c"],"layout":"IPY_MODEL_7862bfbf5e80473d9e56cd57d58e1f25"}},"a850ec4df40e4baf86f217b1ab00642d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e08e0c736164354b57555cf759a9219","placeholder":"​","style":"IPY_MODEL_75b9e1b8c9b4462e867ceb3ff44e4471","value":"Computing widget examples: 100%"}},"9ea54892afb142b1b0b69aa2c809ed9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2edca4b8845748289b59c1c5175c0925","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad4ce50fc88545bf8700efd7762aef93","value":1}},"430f45fa8dc64c498b364658c4cf7c4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_252abbfb995442c18c6cbfcf168af58c","placeholder":"​","style":"IPY_MODEL_2806b7a9ac604946b5123311b89c39af","value":" 1/1 [00:00&lt;00:00,  8.65example/s]"}},"7862bfbf5e80473d9e56cd57d58e1f25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"2e08e0c736164354b57555cf759a9219":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75b9e1b8c9b4462e867ceb3ff44e4471":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2edca4b8845748289b59c1c5175c0925":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad4ce50fc88545bf8700efd7762aef93":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"252abbfb995442c18c6cbfcf168af58c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2806b7a9ac604946b5123311b89c39af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-SnyR6NsFfW","executionInfo":{"status":"ok","timestamp":1756900480215,"user_tz":-120,"elapsed":36225,"user":{"displayName":"Manuel Alberto Romero Garcia","userId":"18136160790858984759"}},"outputId":"40e442a0-6b91-4885-9953-e1fbaff1fb71"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA Available: True\n","GPU: Tesla T4\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n","Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n","You are not authenticated with the Hugging Face Hub in this notebook.\n","If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Setup validated successfully!\n"]}],"source":["import time\n","import torch\n","from transformers import AutoTokenizer, AutoModel\n","from sentence_transformers import SentenceTransformer\n","\n","# Check GPU availability\n","\n","flg_cuda_is_available = torch.cuda.is_available()\n","if flg_cuda_is_available:\n","  print(f\"CUDA Available: {flg_cuda_is_available}\")\n","  print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n","\n","# Validate model and tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n","model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n","\n","print(\"Setup validated successfully!\")"]},{"cell_type":"code","source":["import transformers\n","import sentence_transformers\n","\n","print(f\"{transformers.__version__=}\")\n","print(f\"{sentence_transformers.__version__=}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOgYl2xb3cNN","executionInfo":{"status":"ok","timestamp":1756900480222,"user_tz":-120,"elapsed":5,"user":{"displayName":"Manuel Alberto Romero Garcia","userId":"18136160790858984759"}},"outputId":"049b10dc-7860-40c1-a447-2e3f61354b01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["transformers.__version__='4.55.4'\n","sentence_transformers.__version__='5.1.0'\n"]}]},{"cell_type":"code","source":["from sentence_transformers import SentenceTransformer\n","\n","# Load the pre-trained embedding model\n","model_id = \"BAAI/bge-small-en-v1.5\"\n","model_bsl = SentenceTransformer(model_id)\n","print(\"Model loaded successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mu8kMre0zHMv","executionInfo":{"status":"ok","timestamp":1756900483646,"user_tz":-120,"elapsed":3422,"user":{"displayName":"Manuel Alberto Romero Garcia","userId":"18136160790858984759"}},"outputId":"95d90db4-283b-454f-ba60-ae3dbfb6bdc0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded successfully!\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset, DatasetDict\n","\n","# Load your dataset (replace with your specific dataset)\n","dataset = load_dataset(\"philschmid/finanical-rag-embedding-dataset\")\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9aJoepFhsZxI","executionInfo":{"status":"ok","timestamp":1756900487443,"user_tz":-120,"elapsed":3795,"user":{"displayName":"Manuel Alberto Romero Garcia","userId":"18136160790858984759"}},"outputId":"de2dd836-95a1-4701-cc80-a8d422e35897"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['question', 'context'],\n","        num_rows: 7000\n","    })\n","})"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["print(dataset[\"train\"][0])  # Inspect the data structure"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmHfIfKqwwrP","executionInfo":{"status":"ok","timestamp":1756900487460,"user_tz":-120,"elapsed":15,"user":{"displayName":"Manuel Alberto Romero Garcia","userId":"18136160790858984759"}},"outputId":"c39b60fd-d63b-449f-c219-bae772c0edff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'question': 'What area did NVIDIA initially focus on before expanding to other computationally intensive fields?', 'context': 'Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields.'}\n"]}]},{"cell_type":"code","source":["# from transformers import AutoTokenizer\n","\n","# # Load the tokenizer\n","# tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n","\n","# def preprocess(example):\n","#     return tokenizer(\n","#         example[\"text\"],\n","#         truncation=True,\n","#         padding=\"max_length\",\n","#         #max_length=128\n","#     )\n","\n","# # Apply preprocessing\n","# tokenized_data = dataset.map(preprocess, batched=True)\n","# print(tokenized_data[\"train\"][0])  # Verify the tokenized output"],"metadata":{"id":"y0vbhDzNsaye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sentence_transformers.evaluation import InformationRetrievalEvaluator\n","\n","# Define queries, documents, and relevant pairs\n","queries = {\"query1\": \"What is quantum mechanics?\",\n","           \"query2\": \"Who was the first Roman Emperor?\"\n","           }\n","docs = {\"doc1\": \"Quantum mechanics is the branch of physics that studies the sub-atomic behaviour\",\n","        \"doc2\": \"The sun rises in the east.\",\n","        \"doc3\": \"Augustus (formerly named Octavious, who changed his name after Julius Caesar after his death), is considered the one who ended the Roman Republic and started the empyre\"}\n","relevant_docs = {\"query1\": [\"doc1\"],\n","                 \"query2\": [\"doc2\"]}\n","\n","# Initialize evaluator\n","evaluator_dummy = InformationRetrievalEvaluator(queries, docs, relevant_docs)\n","\n","# Evaluate the model\n","model_bsl.evaluate(evaluator_dummy)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r9qOIawOv0uq","executionInfo":{"status":"ok","timestamp":1756900489351,"user_tz":-120,"elapsed":1887,"user":{"displayName":"Manuel Alberto Romero Garcia","userId":"18136160790858984759"}},"outputId":"252976f1-5791-46ca-adce-73bf50b8e697"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'cosine_accuracy@1': 0.5,\n"," 'cosine_accuracy@3': 1.0,\n"," 'cosine_accuracy@5': 1.0,\n"," 'cosine_accuracy@10': 1.0,\n"," 'cosine_precision@1': 0.5,\n"," 'cosine_precision@3': 0.3333333333333333,\n"," 'cosine_precision@5': 0.2,\n"," 'cosine_precision@10': 0.1,\n"," 'cosine_recall@1': 0.5,\n"," 'cosine_recall@3': 1.0,\n"," 'cosine_recall@5': 1.0,\n"," 'cosine_recall@10': 1.0,\n"," 'cosine_ndcg@10': 0.8154648767857288,\n"," 'cosine_mrr@10': 0.75,\n"," 'cosine_map@100': 0.75}"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["ds = dataset['train']\n","# Add an id column to the dataset\n","ds = ds.add_column(\"id\", range(len(ds)))\n","\n","# split dataset into a 10% test set\n","# 90% train, 10% test + validation\n","ds_train_test = ds.train_test_split(test_size=0.1, seed=42)\n","# Split the 10% test + valid in half test, half valid\n","ds_valid_test = ds_train_test['test'].train_test_split(test_size=0.5, seed=42)\n","# gather everyone if you want to have a single DatasetDict\n","ds_split = DatasetDict({\n","    'train': ds_train_test['train'],\n","    'test': ds_valid_test['test'],\n","    'valid': ds_valid_test['train']})\n","\n"],"metadata":{"id":"w33haYnh5UxV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ds_split"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z9HFkhck7Cdt","executionInfo":{"status":"ok","timestamp":1756900489446,"user_tz":-120,"elapsed":5,"user":{"displayName":"Manuel Alberto Romero Garcia","userId":"18136160790858984759"}},"outputId":"2832281c-6638-4906-cbaa-ecca9b672486"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['question', 'context', 'id'],\n","        num_rows: 6300\n","    })\n","    test: Dataset({\n","        features: ['question', 'context', 'id'],\n","        num_rows: 350\n","    })\n","    valid: Dataset({\n","        features: ['question', 'context', 'id'],\n","        num_rows: 350\n","    })\n","})"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["ds_test = ds_split['test']\n","\n","# Create a mapping of relevant document (1 in our case) for each query\n","relevant_docs = {}  # Query ID to relevant documents (qid => set([relevant_cids])\n","corpus = {}\n","queries = {}\n","\n","for row in ds:\n","    q_id = row['id']\n","    corpus[q_id] = row['context']\n","\n","for row in ds_test:\n","    q_id = row['id']\n","    queries[q_id] = row['question']\n","    relevant_docs[q_id] = [q_id]\n","\n","# Initialize evaluator\n","evaluator_test = InformationRetrievalEvaluator(queries, corpus, relevant_docs\n","                                              # ,score_functions={\"cosine\": cos_sim}\n","                                              )\n","\n","\n","# Evaluate the model\n","evals_test_bsl = model_bsl.evaluate(evaluator_test)\n","\n","print(f\"Baseline model evals: {model_id}\")\n","evals_test_bsl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"huy12o5V7o_W","executionInfo":{"status":"ok","timestamp":1756900979434,"user_tz":-120,"elapsed":8110,"user":{"displayName":"Manuel Alberto Romero Garcia","userId":"18136160790858984759"}},"outputId":"3a5e3e98-589a-4347-87e9-d2589ea00006"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline model evals: BAAI/bge-small-en-v1.5\n"]},{"output_type":"execute_result","data":{"text/plain":["{'cosine_accuracy@1': 0.5942857142857143,\n"," 'cosine_accuracy@3': 0.7371428571428571,\n"," 'cosine_accuracy@5': 0.8,\n"," 'cosine_accuracy@10': 0.8457142857142858,\n"," 'cosine_precision@1': 0.5942857142857143,\n"," 'cosine_precision@3': 0.24571428571428572,\n"," 'cosine_precision@5': 0.15999999999999998,\n"," 'cosine_precision@10': 0.08457142857142856,\n"," 'cosine_recall@1': 0.5942857142857143,\n"," 'cosine_recall@3': 0.7371428571428571,\n"," 'cosine_recall@5': 0.8,\n"," 'cosine_recall@10': 0.8457142857142858,\n"," 'cosine_ndcg@10': 0.7212104601552022,\n"," 'cosine_mrr@10': 0.681048752834467,\n"," 'cosine_map@100': 0.6858932357463235}"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["# Training:\n","\n","[MultipleNegativesRankingLoss](https://sbert.net/docs/package_reference/sentence_transformer/losses.html#multiplenegativesrankingloss)\n"],"metadata":{"id":"JWzSfiWPUWue"}},{"cell_type":"code","source":["from sentence_transformers import SentenceTransformerTrainer, losses, SentenceTransformerModelCardData\n","from sentence_transformers import SentenceTransformerTrainingArguments\n","\n","\n","model = SentenceTransformer(\n","  model_id,\n","  model_kwargs={\"attn_implementation\": \"sdpa\"},\n","  model_card_data=SentenceTransformerModelCardData(\n","      language=\"en\",\n","      license=\"apache-2.0\",\n","      model_name=\"BGE small v1.5 Financial\",\n","  ),\n",")\n","train_loss = losses.MultipleNegativesRankingLoss(model) # anchor + positive\n","\n","\n","# Training dataset\n","ds_train = (ds_split['train']\n","            .select_columns([\"context\", \"question\"])\n","            .rename_column(\"context\", \"positive\")\n","            .rename_column(\"question\", \"anchor\")\n","            )\n","\n","# Evaluator\n","ds_valid = ds_split['valid']\n","\n","relevant_docs = {}\n","corpus = {}\n","queries = {}\n","for row in ds_valid:\n","    q_id = row['id']\n","    corpus[q_id] = row['context']\n","    queries[q_id] = row['question']\n","    relevant_docs[q_id] = [q_id]\n","\n","evaluator_valid = InformationRetrievalEvaluator(\n","    queries, corpus, relevant_docs\n","                                              )\n","\n","# Define training arguments\n","args = SentenceTransformerTrainingArguments(\n","    output_dir=\"bge-small-financial\", # output directory and hugging face model ID\n","    num_train_epochs=1,                         # number of epochs\n","    per_device_train_batch_size=32,             # train batch size\n","    gradient_accumulation_steps=16,             # for a global batch size of 512\n","    per_device_eval_batch_size=16,              # evaluation batch size\n","    warmup_ratio=0.1,                           # warmup ratio\n","    learning_rate=2e-5,                         # learning rate, 2e-5 is a good value\n","    lr_scheduler_type=\"cosine\",                 # use cosine learning rate scheduler\n","    optim=\"adamw_torch_fused\",                  # use fused adamw optimizer\n","    eval_strategy=\"epoch\",                      # evaluate after each epoch\n","    save_strategy=\"epoch\",                      # save after each epoch\n","    logging_steps=10,                           # log every 10 steps\n","    save_total_limit=3,                         # save only the last 3 models\n","    load_best_model_at_end=True,                # load the best model when training ends\n","    report_to=\"none\",\n","    metric_for_best_model='eval_cosine_recall@1'\n",")\n","\n","\n","trainer = SentenceTransformerTrainer(\n","    model=model,\n","    args=args,  # training arguments\n","    train_dataset=ds_train,\n","    loss=train_loss,\n","    evaluator=evaluator_valid,\n",")\n","\n","# start training, the model will be automatically saved to the hub and the output directory\n","tm_start = time.perf_counter()\n","trainer.train()\n","tm_end = time.perf_counter()\n","tm_process = tm_end - tm_start\n","print(f\"Training time: {tm_process:.2f}s\")\n","\n","\n","# save the best model\n","trainer.save_model()\n","\n","fine_tuned_model = SentenceTransformer(\n","    args.output_dir, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":196,"referenced_widgets":["29ca2a51b8234e80a8aecc0685611054","a850ec4df40e4baf86f217b1ab00642d","9ea54892afb142b1b0b69aa2c809ed9b","430f45fa8dc64c498b364658c4cf7c4c","7862bfbf5e80473d9e56cd57d58e1f25","2e08e0c736164354b57555cf759a9219","75b9e1b8c9b4462e867ceb3ff44e4471","2edca4b8845748289b59c1c5175c0925","ad4ce50fc88545bf8700efd7762aef93","252abbfb995442c18c6cbfcf168af58c","2806b7a9ac604946b5123311b89c39af"]},"id":"iLCywHRmMX0F","executionInfo":{"status":"ok","timestamp":1756901077936,"user_tz":-120,"elapsed":70006,"user":{"displayName":"Manuel Alberto Romero Garcia","userId":"18136160790858984759"}},"outputId":"153785d2-4590-4d5e-d448-f7c4b4e02441"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29ca2a51b8234e80a8aecc0685611054"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:sentence_transformers.data_collator:Column 'anchor' is at index 1, whereas a column with this name is usually expected at index 0. Note that the column order can be important for some losses, e.g. MultipleNegativesRankingLoss will always consider the first column as the anchor and the second as the positive, regardless of the dataset column names. Consider renaming the columns to match the expected order, e.g.:\n","dataset = dataset.select_columns(['anchor', 'positive', 'negative'])\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [13/13 00:57, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Cosine Accuracy@1</th>\n","      <th>Cosine Accuracy@3</th>\n","      <th>Cosine Accuracy@5</th>\n","      <th>Cosine Accuracy@10</th>\n","      <th>Cosine Precision@1</th>\n","      <th>Cosine Precision@3</th>\n","      <th>Cosine Precision@5</th>\n","      <th>Cosine Precision@10</th>\n","      <th>Cosine Recall@1</th>\n","      <th>Cosine Recall@3</th>\n","      <th>Cosine Recall@5</th>\n","      <th>Cosine Recall@10</th>\n","      <th>Cosine Ndcg@10</th>\n","      <th>Cosine Mrr@10</th>\n","      <th>Cosine Map@100</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.321800</td>\n","      <td>No log</td>\n","      <td>0.885714</td>\n","      <td>0.957143</td>\n","      <td>0.974286</td>\n","      <td>0.982857</td>\n","      <td>0.885714</td>\n","      <td>0.319048</td>\n","      <td>0.194857</td>\n","      <td>0.098286</td>\n","      <td>0.885714</td>\n","      <td>0.957143</td>\n","      <td>0.974286</td>\n","      <td>0.982857</td>\n","      <td>0.938499</td>\n","      <td>0.923773</td>\n","      <td>0.924779</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training time: 63.00s\n"]}]},{"cell_type":"code","source":["fine_tuned_model.model_card_data,"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dLb5q1n5d_HF","executionInfo":{"status":"ok","timestamp":1756901169464,"user_tz":-120,"elapsed":50,"user":{"displayName":"Manuel Alberto Romero Garcia","userId":"18136160790858984759"}},"outputId":"581382aa-8240-424a-eb13-ffa33757504d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SentenceTransformerModelCardData(language=[], license=None, model_name=None, model_id=None, train_datasets=[], eval_datasets=[], task_name='semantic textual similarity, semantic search, paraphrase mining, text classification, clustering, and more', tags=['sentence-transformers', 'sentence-similarity', 'feature-extraction', 'dense'], local_files_only=False, generate_widget_examples=True, base_model=None, base_model_revision=None, non_default_hyperparameters={}, all_hyperparameters={}, eval_results_dict={}, training_logs=[], widget=[], predict_example=None, label_example_list=[], code_carbon_callback=None, citations={}, best_model_step=None, first_save=True, widget_step=-1, pipeline_tag='sentence-similarity', library_name='sentence-transformers', version={'python': '3.12.11', 'sentence_transformers': '5.1.0', 'transformers': '4.55.4', 'torch': '2.8.0+cu126', 'accelerate': '1.10.1', 'datasets': '4.0.0', 'tokenizers': '0.21.4'})"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Evaluate the model\n","evals_test_ft = fine_tuned_model.evaluate(evaluator_test)\n","\n","print(f\"FT model evals: {model_id}\")\n","evals_test_ft"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4cdSfwknOfCQ","executionInfo":{"status":"ok","timestamp":1756901198882,"user_tz":-120,"elapsed":8396,"user":{"displayName":"Manuel Alberto Romero Garcia","userId":"18136160790858984759"}},"outputId":"9fae24b6-d0e3-45ab-fcc8-7627b25d1c43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FT model evals: BAAI/bge-small-en-v1.5\n"]},{"output_type":"execute_result","data":{"text/plain":["{'cosine_accuracy@1': 0.6542857142857142,\n"," 'cosine_accuracy@3': 0.7971428571428572,\n"," 'cosine_accuracy@5': 0.8457142857142858,\n"," 'cosine_accuracy@10': 0.8914285714285715,\n"," 'cosine_precision@1': 0.6542857142857142,\n"," 'cosine_precision@3': 0.2657142857142857,\n"," 'cosine_precision@5': 0.16914285714285712,\n"," 'cosine_precision@10': 0.08914285714285713,\n"," 'cosine_recall@1': 0.6542857142857142,\n"," 'cosine_recall@3': 0.7971428571428572,\n"," 'cosine_recall@5': 0.8457142857142858,\n"," 'cosine_recall@10': 0.8914285714285715,\n"," 'cosine_ndcg@10': 0.7718514612605226,\n"," 'cosine_mrr@10': 0.7335589569161,\n"," 'cosine_map@100': 0.7368102729714265}"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":[],"metadata":{"id":"uUPzqM9IeW7I"},"execution_count":null,"outputs":[]}]}